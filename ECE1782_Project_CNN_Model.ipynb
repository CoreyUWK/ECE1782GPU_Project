{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ECE1782 Project CNN Model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSPCom-KmApV"
      },
      "source": [
        "# Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7KBpffWzlxH"
      },
      "source": [
        "### Import TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAve6DCL4JH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc579c6-91bb-4632-b75c-2f941d185a2f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pprint\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 20 02:33:05 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIcUVRaYKcEW"
      },
      "source": [
        "Paper CNN Tensorflow Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYZtL38vKe_x",
        "outputId": "2362a7e4-ce64-4c52-cc54-4f34f10a1165"
      },
      "source": [
        "# Setup input as all ones\n",
        "input_shape = (1, 1, 56, 100) # Batch Size, Input Channels, Rows, Columns\n",
        "x = tf.ones(input_shape)\n",
        "\n",
        "# Setup model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Convolution Layer 1: 1 Input, 64 Output, Same dimensions\n",
        "model.add(layers.Conv2D(64, (8, 8), activation='relu', strides=1, padding='same', input_shape=input_shape[1:], kernel_initializer=\"ones\", bias_initializer=\"ones\", data_format='channels_first'))\n",
        "#cov1 = model(x)\n",
        "#print(\"cov1:\", cov1.shape)\n",
        "\n",
        "# Maxpool 1: \n",
        "model.add(layers.MaxPooling2D((2, 2), strides=2, padding='same', data_format='channels_first'))\n",
        "#maxpool1 = model(x)\n",
        "#print(\"maxpool1:\", maxpool1.shape)\n",
        "\n",
        "# Convolution Layer 2: 64 Input, 64 Output, Same dimensions\n",
        "model.add(layers.Conv2D(64, (4, 4), activation='relu', strides=1, padding='same', kernel_initializer=\"ones\", bias_initializer=\"ones\", data_format='channels_first'))\n",
        "#cov2 = model(x)\n",
        "#print(\"cov2:\", cov2.shape)\n",
        "\n",
        "# Maxpool 2: \n",
        "model.add(layers.MaxPooling2D((2, 2), strides=2, padding='same', data_format='channels_first'))\n",
        "#maxpool2 = model(x)\n",
        "#print(\"maxpool2:\", maxpool2.shape)\n",
        "\n",
        "# Convolution Layer 3: 64 Input, 64 Output, Same dimensions\n",
        "model.add(layers.Conv2D(64, (2, 2), activation='relu', strides=1, padding='same', kernel_initializer=\"ones\", bias_initializer=\"ones\", data_format='channels_first'))\n",
        "#cov3 = model(x)\n",
        "#print(\"cov3:\", cov3.shape)\n",
        "\n",
        "# Fully Connection Layers\n",
        "##model.add(layers.GlobalAveragePooling2D()) # Not use\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu', kernel_initializer=\"ones\", bias_initializer=\"ones\"))\n",
        "model.add(layers.Dense(3, activation='softmax', kernel_initializer=\"ones\", bias_initializer=\"ones\"))\n",
        "##model.add(layers.Softmax()) # Not use\n",
        "#model.summary()\n",
        "\n",
        "# Get timing results\n",
        "runs = 10\n",
        "for i in range(0, runs):\n",
        "  start_time = time.time()\n",
        "  y = model(x)\n",
        "  print(\"--- %s ms for 1 ---\" % ((time.time() - start_time)*1000))\n",
        "\n",
        "# To save to file \n",
        "# https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_deep-learning-computation/read-write.ipynb\n",
        "\n",
        "# Print Results\n",
        "print(\"Input:\")\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "print(\"Output:\")\n",
        "print(y.shape)\n",
        "#print(tf.shape(y))\n",
        "tf.print(y, summarize=5)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 10600.562572479248 ms for 1 ---\n",
            "--- 8.234739303588867 ms for 1 ---\n",
            "--- 14.50490951538086 ms for 1 ---\n",
            "--- 5.494832992553711 ms for 1 ---\n",
            "--- 5.785226821899414 ms for 1 ---\n",
            "--- 14.641046524047852 ms for 1 ---\n",
            "--- 13.381719589233398 ms for 1 ---\n",
            "--- 12.346029281616211 ms for 1 ---\n",
            "--- 6.774187088012695 ms for 1 ---\n",
            "--- 6.399631500244141 ms for 1 ---\n",
            "Input:\n",
            "(1, 1, 56, 100)\n",
            "tf.Tensor(\n",
            "[[[[1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]]]], shape=(1, 1, 56, 100), dtype=float32)\n",
            "Output:\n",
            "(1, 3)\n",
            "[[0.333333343 0.333333343 0.333333343]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Model Timing Results when Batching instead of looping"
      ],
      "metadata": {
        "id": "kHRqpMT_fbS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup input as all ones\n",
        "input_shape = (100, 1, 56, 100) # Batch Size, Input Channels, Rows, Columns\n",
        "x = tf.ones(input_shape)\n",
        "\n",
        "# Setup model\n",
        "model_batch = models.Sequential()\n",
        "\n",
        "# Convolution Layer 1: 1 Input, 64 Output, Same dimensions\n",
        "model_batch.add(layers.Conv2D(64, (8, 8), activation='relu', strides=1, padding='same', input_shape=input_shape[1:], kernel_initializer=\"ones\", bias_initializer=\"ones\", data_format='channels_first'))\n",
        "#cov1 = model_batch(x)\n",
        "#print(\"cov1:\", cov1.shape)\n",
        "\n",
        "# Maxpool 1: \n",
        "model_batch.add(layers.MaxPooling2D((2, 2), strides=2, padding='same', data_format='channels_first'))\n",
        "#maxpool1 = model_batch(x)\n",
        "#print(\"maxpool1:\", maxpool1.shape)\n",
        "\n",
        "# Convolution Layer 2: 64 Input, 64 Output, Same dimensions\n",
        "model_batch.add(layers.Conv2D(64, (4, 4), activation='relu', strides=1, padding='same', kernel_initializer=\"ones\", bias_initializer=\"ones\", data_format='channels_first'))\n",
        "#cov2 = model_batch(x)\n",
        "#print(\"cov2:\", cov2.shape)\n",
        "\n",
        "# Maxpool 2: \n",
        "model_batch.add(layers.MaxPooling2D((2, 2), strides=2, padding='same', data_format='channels_first'))\n",
        "#maxpool2 = model_batch(x)\n",
        "#print(\"maxpool2:\", maxpool2.shape)\n",
        "\n",
        "# Convolution Layer 3: 64 Input, 64 Output, Same dimensions\n",
        "model_batch.add(layers.Conv2D(64, (2, 2), activation='relu', strides=1, padding='same', kernel_initializer=\"ones\", bias_initializer=\"ones\", data_format='channels_first'))\n",
        "#cov3 = model_batch(x)\n",
        "#print(\"cov3:\", cov3.shape)\n",
        "\n",
        "# Fully Connection Layers\n",
        "##model_batch.add(layers.GlobalAveragePooling2D()) # Not use\n",
        "model_batch.add(layers.Flatten())\n",
        "model_batch.add(layers.Dense(256, activation='relu', kernel_initializer=\"ones\", bias_initializer=\"ones\"))\n",
        "model_batch.add(layers.Dense(3, activation='softmax', kernel_initializer=\"ones\", bias_initializer=\"ones\"))\n",
        "##model_batch.add(layers.Softmax()) # Not use\n",
        "#model_batch.summary()\n",
        "\n",
        "# Get timing results\n",
        "runs = 10\n",
        "for i in range(0, runs):\n",
        "  start_time = time.time()\n",
        "  y = model_batch(x)\n",
        "  print(\"--- %s ms for 1 ---\" % ((time.time() - start_time)*1000))\n",
        "\n",
        "# To save to file \n",
        "# https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_deep-learning-computation/read-write.ipynb\n",
        "\n",
        "# Print Results\n",
        "print(\"Input:\")\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "print(\"Output:\")\n",
        "print(y.shape)\n",
        "#print(tf.shape(y))\n",
        "tf.print(y, summarize=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8aejG7ffX9G",
        "outputId": "bc9d58c7-9ccb-4cce-bf12-2eb8aa02625e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 332.841157913208 ms for 1 ---\n",
            "--- 4.761934280395508 ms for 1 ---\n",
            "--- 4.318952560424805 ms for 1 ---\n",
            "--- 4.299640655517578 ms for 1 ---\n",
            "--- 4.454374313354492 ms for 1 ---\n",
            "--- 4.554271697998047 ms for 1 ---\n",
            "--- 4.196643829345703 ms for 1 ---\n",
            "--- 4.244565963745117 ms for 1 ---\n",
            "--- 4.448890686035156 ms for 1 ---\n",
            "--- 4.433631896972656 ms for 1 ---\n",
            "Input:\n",
            "(100, 1, 56, 100)\n",
            "tf.Tensor(\n",
            "[[[[1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]]]], shape=(100, 1, 56, 100), dtype=float32)\n",
            "Output:\n",
            "(100, 3)\n",
            "[[0.333333343 0.333333343 0.333333343]\n",
            " [0.333333343 0.333333343 0.333333343]\n",
            " [0.333333343 0.333333343 0.333333343]\n",
            " [0.333333343 0.333333343 0.333333343]\n",
            " [0.333333343 0.333333343 0.333333343]\n",
            " ...\n",
            " [0.333333343 0.333333343 0.333333343]\n",
            " [0.333333343 0.333333343 0.333333343]\n",
            " [0.333333343 0.333333343 0.333333343]\n",
            " [0.333333343 0.333333343 0.333333343]\n",
            " [0.333333343 0.333333343 0.333333343]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try Model but with MaxPool Stride=1"
      ],
      "metadata": {
        "id": "QK8PqN8SlhAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup input as all ones\n",
        "input_shape = (1, 1, 56, 100) # Batch Size, Input Channels, Rows, Columns\n",
        "x = tf.ones(input_shape)\n",
        "\n",
        "# Setup model\n",
        "model_maxpool_stride1 = models.Sequential()\n",
        "\n",
        "# Convolution Layer 1: 1 Input, 64 Output, Same dimensions\n",
        "model_maxpool_stride1.add(layers.Conv2D(64, (8, 8), activation='relu', strides=1, padding='same', input_shape=input_shape[1:], kernel_initializer=\"ones\", bias_initializer=\"ones\", data_format='channels_first'))\n",
        "#cov1 = model_maxpool_stride1(x)\n",
        "#print(\"cov1:\", cov1.shape)\n",
        "\n",
        "# Maxpool 1: \n",
        "model_maxpool_stride1.add(layers.MaxPooling2D((2, 2), strides=1, padding='same', data_format='channels_first'))\n",
        "#maxpool1 = model_maxpool_stride1(x)\n",
        "#print(\"maxpool1:\", maxpool1.shape)\n",
        "\n",
        "# Convolution Layer 2: 64 Input, 64 Output, Same dimensions\n",
        "model_maxpool_stride1.add(layers.Conv2D(64, (4, 4), activation='relu', strides=1, padding='same', kernel_initializer=\"ones\", bias_initializer=\"ones\", data_format='channels_first'))\n",
        "#cov2 = model_maxpool_stride1(x)\n",
        "#print(\"cov2:\", cov2.shape)\n",
        "\n",
        "# Maxpool 2: \n",
        "model_maxpool_stride1.add(layers.MaxPooling2D((2, 2), strides=1, padding='same', data_format='channels_first'))\n",
        "#maxpool2 = model_maxpool_stride1(x)\n",
        "#print(\"maxpool2:\", maxpool2.shape)\n",
        "\n",
        "# Convolution Layer 3: 64 Input, 64 Output, Same dimensions\n",
        "model_maxpool_stride1.add(layers.Conv2D(64, (2, 2), activation='relu', strides=1, padding='same', kernel_initializer=\"ones\", bias_initializer=\"ones\", data_format='channels_first'))\n",
        "#cov3 = model_maxpool_stride1(x)\n",
        "#print(\"cov3:\", cov3.shape)\n",
        "\n",
        "# Fully Connection Layers\n",
        "##model_maxpool_stride1.add(layers.GlobalAveragePooling2D()) # Not use\n",
        "model_maxpool_stride1.add(layers.Flatten())\n",
        "model_maxpool_stride1.add(layers.Dense(256, activation='relu', kernel_initializer=\"ones\", bias_initializer=\"ones\"))\n",
        "model_maxpool_stride1.add(layers.Dense(3, activation='softmax', kernel_initializer=\"ones\", bias_initializer=\"ones\"))\n",
        "##model_maxpool_stride1.add(layers.Softmax()) # Not use\n",
        "#model_maxpool_stride1.summary()\n",
        "\n",
        "# Get timing results\n",
        "runs = 10\n",
        "for i in range(0, runs):\n",
        "  start_time = time.time()\n",
        "  y = model_maxpool_stride1(x)\n",
        "  print(\"--- %s ms for 1 ---\" % ((time.time() - start_time)*1000))\n",
        "\n",
        "# To save to file \n",
        "# https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_deep-learning-computation/read-write.ipynb\n",
        "\n",
        "# Print Results\n",
        "print(\"Input:\")\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "print(\"Output:\")\n",
        "print(y.shape)\n",
        "#print(tf.shape(y))\n",
        "tf.print(y, summarize=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fsxKyG1lmRw",
        "outputId": "9d276505-fd65-4f4a-9040-26c10342468d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 80.28817176818848 ms for 1 ---\n",
            "--- 5.268335342407227 ms for 1 ---\n",
            "--- 4.271984100341797 ms for 1 ---\n",
            "--- 4.853487014770508 ms for 1 ---\n",
            "--- 4.602670669555664 ms for 1 ---\n",
            "--- 4.489898681640625 ms for 1 ---\n",
            "--- 4.712343215942383 ms for 1 ---\n",
            "--- 4.301786422729492 ms for 1 ---\n",
            "--- 4.383563995361328 ms for 1 ---\n",
            "--- 4.228830337524414 ms for 1 ---\n",
            "Input:\n",
            "(1, 1, 56, 100)\n",
            "tf.Tensor(\n",
            "[[[[1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]]]], shape=(1, 1, 56, 100), dtype=float32)\n",
            "Output:\n",
            "(1, 3)\n",
            "[[0.333333343 0.333333343 0.333333343]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try with random weight values to see if the fast times from above tests is due to some caching"
      ],
      "metadata": {
        "id": "Fl5VxItMnKzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup input as all ones\n",
        "input_shape = (1, 1, 56, 100) # Batch Size, Input Channels, Rows, Columns\n",
        "x = tf.ones(input_shape)\n",
        "\n",
        "init_val = \"RandomUniform\"\n",
        "\n",
        "# Setup model\n",
        "model_rand = models.Sequential()\n",
        "\n",
        "# Convolution Layer 1: 1 Input, 64 Output, Same dimensions\n",
        "model_rand.add(layers.Conv2D(64, (8, 8), activation='relu', strides=1, padding='same', input_shape=input_shape[1:], kernel_initializer=init_val, bias_initializer=init_val, data_format='channels_first'))\n",
        "#cov1 = model_rand(x)\n",
        "#print(\"cov1:\", cov1.shape)\n",
        "\n",
        "# Maxpool 1: \n",
        "model_rand.add(layers.MaxPooling2D((2, 2), strides=1, padding='same', data_format='channels_first'))\n",
        "#maxpool1 = model_rand(x)\n",
        "#print(\"maxpool1:\", maxpool1.shape)\n",
        "\n",
        "# Convolution Layer 2: 64 Input, 64 Output, Same dimensions\n",
        "model_rand.add(layers.Conv2D(64, (4, 4), activation='relu', strides=1, padding='same', kernel_initializer=init_val, bias_initializer=init_val, data_format='channels_first'))\n",
        "#cov2 = model_rand(x)\n",
        "#print(\"cov2:\", cov2.shape)\n",
        "\n",
        "# Maxpool 2: \n",
        "model_rand.add(layers.MaxPooling2D((2, 2), strides=1, padding='same', data_format='channels_first'))\n",
        "#maxpool2 = model_rand(x)\n",
        "#print(\"maxpool2:\", maxpool2.shape)\n",
        "\n",
        "# Convolution Layer 3: 64 Input, 64 Output, Same dimensions\n",
        "model_rand.add(layers.Conv2D(64, (2, 2), activation='relu', strides=1, padding='same', kernel_initializer=init_val, bias_initializer=init_val, data_format='channels_first'))\n",
        "#cov3 = model_rand(x)\n",
        "#print(\"cov3:\", cov3.shape)\n",
        "\n",
        "# Fully Connection Layers\n",
        "##model_rand.add(layers.GlobalAveragePooling2D()) # Not use\n",
        "model_rand.add(layers.Flatten())\n",
        "model_rand.add(layers.Dense(256, activation='relu', kernel_initializer=init_val, bias_initializer=init_val))\n",
        "model_rand.add(layers.Dense(3, activation='softmax', kernel_initializer=init_val, bias_initializer=init_val))\n",
        "##model_rand.add(layers.Softmax()) # Not use\n",
        "#model_rand.summary()\n",
        "\n",
        "# Get timing results\n",
        "runs = 10\n",
        "for i in range(0, runs):\n",
        "  start_time = time.time()\n",
        "  y = model_rand(x)\n",
        "  print(\"--- %s ms for 1 ---\" % ((time.time() - start_time)*1000))\n",
        "\n",
        "# To save to file \n",
        "# https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_deep-learning-computation/read-write.ipynb\n",
        "\n",
        "# Print Results\n",
        "print(\"Input:\")\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "print(\"Output:\")\n",
        "print(y.shape)\n",
        "#print(tf.shape(y))\n",
        "tf.print(y, summarize=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ2CUYRUnVg4",
        "outputId": "88104ed3-661d-4a08-8837-fc09e6027d56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 4.449129104614258 ms for 1 ---\n",
            "--- 4.121065139770508 ms for 1 ---\n",
            "--- 4.470586776733398 ms for 1 ---\n",
            "--- 4.921436309814453 ms for 1 ---\n",
            "--- 5.092144012451172 ms for 1 ---\n",
            "--- 4.525661468505859 ms for 1 ---\n",
            "--- 4.509687423706055 ms for 1 ---\n",
            "--- 4.578351974487305 ms for 1 ---\n",
            "--- 5.162715911865234 ms for 1 ---\n",
            "--- 4.436492919921875 ms for 1 ---\n",
            "Input:\n",
            "(1, 1, 56, 100)\n",
            "tf.Tensor(\n",
            "[[[[1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   ...\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]\n",
            "   [1. 1. 1. ... 1. 1. 1.]]]], shape=(1, 1, 56, 100), dtype=float32)\n",
            "Output:\n",
            "(1, 3)\n",
            "[[0.292113513 0.263940901 0.443945616]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D-inrpf3QB1"
      },
      "source": [
        "Now Try with objax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEtcYPts3Oz_"
      },
      "source": [
        "#Install Objax\n",
        "!pip --quiet install  objax\n",
        "import objax\n",
        "import tensorflow as tf \n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import jax.numpy as jn\n",
        "import random \n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import  pprint\n",
        "from tensorflow.keras import datasets, layers, models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5Z4WGTT3Wdu"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "X_train = train_images.transpose(0, 3, 1, 2) / 255.0\n",
        "Y_train = train_labels.flatten()\n",
        "X_test = test_images.transpose(0, 3, 1, 2) / 255.0\n",
        "Y_test = test_labels.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt17AHZl4AtH",
        "outputId": "cb072a0f-675a-4b41-a5c0-19a70578a71a"
      },
      "source": [
        "class ConvNet(objax.Module):\n",
        "  def __init__(self, number_of_channels = 3, number_of_classes = 10):\n",
        "    self.conv_1 = objax.nn.Sequential([objax.nn.Conv2D(number_of_channels, 32, 3, padding=\"VALID\"), objax.functional.relu])\n",
        "    self.conv_2 = objax.nn.Sequential([objax.nn.Conv2D(32, 64, 3, padding=\"VALID\"), objax.functional.relu])\n",
        "    self.conv_3 = objax.nn.Sequential([objax.nn.Conv2D(64, 64, 3, padding=\"VALID\"), objax.functional.relu])\n",
        "\n",
        "    self.linear1 = objax.nn.Sequential([objax.nn.Linear(1024, 64), objax.functional.relu])\n",
        "    self.linear2 = objax.nn.Linear(64, number_of_classes)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    #print(x.shape)\n",
        "    x = objax.functional.max_pool_2d(self.conv_1(x), 2)\n",
        "    #print(x.shape)\n",
        "    x = objax.functional.max_pool_2d(self.conv_2(x), 2)\n",
        "    #print(x.shape)\n",
        "    x = self.conv_3(x)\n",
        "    #print(x.shape)\n",
        "    x = objax.functional.flatten(x)\n",
        "    #print(x.shape)\n",
        "    x = self.linear1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.linear2(x)\n",
        "    #print(x.shape)\n",
        "    return x\n",
        "\n",
        "#The following line creates the CNN\n",
        "model = ConvNet()\n",
        "#You can examine the architecture of our CNN by calling model.vars()\n",
        "print(model.vars())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(ConvNet).conv_1(Sequential)[0](Conv2D).b        32 (32, 1, 1)\n",
            "(ConvNet).conv_1(Sequential)[0](Conv2D).w       864 (3, 3, 3, 32)\n",
            "(ConvNet).conv_2(Sequential)[0](Conv2D).b        64 (64, 1, 1)\n",
            "(ConvNet).conv_2(Sequential)[0](Conv2D).w     18432 (3, 3, 32, 64)\n",
            "(ConvNet).conv_3(Sequential)[0](Conv2D).b        64 (64, 1, 1)\n",
            "(ConvNet).conv_3(Sequential)[0](Conv2D).w     36864 (3, 3, 64, 64)\n",
            "(ConvNet).linear1(Sequential)[0](Linear).b       64 (64,)\n",
            "(ConvNet).linear1(Sequential)[0](Linear).w    65536 (1024, 64)\n",
            "(ConvNet).linear2(Linear).b                      10 (10,)\n",
            "(ConvNet).linear2(Linear).w                     640 (64, 10)\n",
            "+Total(10)                                   122570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aD4zE3YBzdY"
      },
      "source": [
        "#Define loss function as averaged value of of cross entropies\n",
        "def loss_function(x, labels):\n",
        "    logit = model(x)\n",
        "    return objax.functional.loss.cross_entropy_logits_sparse(logit, labels).mean()\n",
        "\n",
        "#Define a prediction function\n",
        "predict = objax.Jit(lambda x: objax.functional.softmax(model(x)), model.vars()) \n",
        "\n",
        "#Create an object that can be used to calculate the gradient and value of loss_function\n",
        "gv= objax.GradValues(loss_function, model.vars())\n",
        "\n",
        "#Create an object that can be used to provide trainable variables in the model\n",
        "tv = objax.ModuleList(objax.TrainRef(x) for x in model.vars().subset(objax.TrainVar))\n",
        "\n",
        "opt = objax.optimizer.Adam(model.vars())\n",
        "\n",
        "#Training routine\n",
        "def train_op(x, y, learning_rate):\n",
        "    lr = learning_rate\n",
        "    gradient, loss_value = gv(x, y)   # calculate gradient and loss value \"backprop\"\n",
        "    for grad, params in zip(gradient, tv.vars()):\n",
        "      params.value -= lr * grad\n",
        "    #opt(lr, gradient)  # update weights\n",
        "    return loss_value                      # return loss value\n",
        "\n",
        "#make train_op (much) faster using JIT compilation\n",
        "train_op = objax.Jit(train_op, gv.vars() + tv.vars())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1tFhzE9CSIy"
      },
      "source": [
        "def train(EPOCHS = 10, BATCH = 32, LEARNING_RATE = 9e-4):\n",
        "  avg_train_loss_epoch = []\n",
        "  train_acc_epoch = []\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "      avg_train_loss = 0 # (averaged) training loss per batch\n",
        "      train_acc = 0      # training accuracy per batch\n",
        "\n",
        "      # shuffle the examples prior to training to remove correlation \n",
        "      train_indices = np.arange(len(X_train)) \n",
        "      #np.random.shuffle(train_indices)\n",
        "      for it in range(0, X_train.shape[0], BATCH):\n",
        "          #print(\"{}:{}\".format(it, it + BATCH))\n",
        "          batch = train_indices[it : it + BATCH] #PUT YOUR CODE HERE#\n",
        "          #print(X_train[batch])\n",
        "          #print(len(batch))\n",
        "          avg_train_loss += float(train_op(X_train[batch], Y_train[batch], LEARNING_RATE)[0]) * len(batch)\n",
        "          train_prediction = predict(X_train[batch]).argmax(1)\n",
        "          train_acc += (np.array(train_prediction).flatten() == Y_train[batch]).sum()\n",
        "      train_acc_epoch.append(train_acc/X_train.shape[0])\n",
        "      avg_train_loss_epoch.append(avg_train_loss/X_train.shape[0])\n",
        "      print('Epoch %04d Training Loss %.2f Training Accuracy %.2f' % (epoch + 1, avg_train_loss/X_train.shape[0], 100*train_acc/X_train.shape[0]))\n",
        "\n",
        "  #Plot training loss\n",
        "  plt.title(\"Train Loss\")\n",
        "  plt.plot(avg_train_loss_epoch, label=\"Train\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"Train\")\n",
        "  plt.plot(train_acc_epoch, label=\"Train\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy (%)\")\n",
        "  plt.legend(loc='best')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi-jTmwFCUKe"
      },
      "source": [
        "def test(BATCH = 32):\n",
        "  avg_test_loss = 0 # (averaged) test loss per batch\n",
        "  test_acc = 0      # test accuracy per batch\n",
        "\n",
        "  # run test set\n",
        "  test_indices = np.arange(len(X_test)) \n",
        "  #np.random.shuffle(test_indices)    \n",
        "  for it in range(0, X_test.shape[0], BATCH):\n",
        "      batch = test_indices[it : it + BATCH] #PUT YOUR CODE HERE#\n",
        "      avg_test_loss += float(loss_function(X_test[batch], Y_test[batch])) * len(batch)\n",
        "      test_prediction = predict(X_test[batch]).argmax(1)\n",
        "      test_acc += (np.array(test_prediction).flatten() == Y_test[batch]).sum()\n",
        "  test_acc = (test_acc/X_test.shape[0])\n",
        "  avg_test_loss = (avg_test_loss/X_test.shape[0])\n",
        "\n",
        "  print('Test Loss %.2f Test Accuracy %.2f' % (avg_test_loss, 100*test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "lrsiZ8lyCVou",
        "outputId": "533d050f-d624-4b00-871a-e6e525ba141b"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0001 Training Loss 2.30 Training Accuracy 13.63\n",
            "Epoch 0002 Training Loss 2.30 Training Accuracy 13.68\n",
            "Epoch 0003 Training Loss 2.30 Training Accuracy 13.67\n",
            "Epoch 0004 Training Loss 2.30 Training Accuracy 13.68\n",
            "Epoch 0005 Training Loss 2.30 Training Accuracy 13.68\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-233f65d7a58a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(EPOCHS, BATCH, LEARNING_RATE)\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0;31m#print(X_train[batch])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0;31m#print(len(batch))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m           \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m           \u001b[0mtrain_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/objax/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;34m\"\"\"Call the compiled version of the function or module.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchanges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3laflfYCXom"
      },
      "source": [
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra Debug Stuff - Can Ignore"
      ],
      "metadata": {
        "id": "7Xfp9-6gbtMf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "cYWd7O7lPYYD",
        "outputId": "d81dd0ad-bfbc-4d8c-e45c-48abfb1775e4"
      },
      "source": [
        "# With `padding` as \"same\".\n",
        "input_shape = (1, 4, 5, 1)\n",
        "x = tf.ones(input_shape)\n",
        "model = tf.keras.layers.Conv2D(1, 2, padding=\"same\", input_shape=input_shape, kernel_initializer=\"ones\", bias_initializer=\"zeros\")\n",
        "y = model(x)\n",
        "\n",
        "print(\"Input:\")\n",
        "pprint.pprint(x)\n",
        "print(\"Output:\")\n",
        "pprint.pprint(y)\n",
        "\n",
        "print(\"Weights:\")\n",
        "print(model.get_config(), model.get_weights())\n",
        "weights = model.get_weights()\n",
        "pprint.pprint(weights)\n",
        "\n",
        "#input = tf.ones((5, 4), dtype=tf.float32)\n",
        "#kernel = tf.ones((2, 2), dtype=tf.float32)\n",
        "#print(input)\n",
        "#conv = tf.nn.conv2d(input, kernel, 1, 'SAME')\n",
        "#print(conv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-73a22564a93b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ones\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zeros\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1082\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1083\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mconvolution_op\u001b[0;34m(self, inputs, kernel)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_data_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         name=self.__class__.__name__)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1157\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1289\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1292\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2765\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2766\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2767\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2768\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2769\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYIL88WPgtqV"
      },
      "source": [
        "# With `padding` as \"same\".\n",
        "input_shape = (1, 56, 100, 1)\n",
        "x = tf.ones(input_shape)\n",
        "model = tf.keras.layers.Conv2D(1, 2, padding=\"same\", input_shape=input_shape[1:], kernel_initializer=\"ones\", bias_initializer=\"zeros\")\n",
        "y = model(x)\n",
        "\n",
        "print(\"Input:\")\n",
        "pprint.pprint(x)\n",
        "print(\"Output:\")\n",
        "pprint.pprint(y)\n",
        "\n",
        "print(\"Weights:\")\n",
        "print(model.get_config(), model.get_weights())\n",
        "weights = model.get_weights()\n",
        "pprint.pprint(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSOBU_OmiFdo"
      },
      "source": [
        "When starting with new runtime: \n",
        "27.790482997894287 seconds for 1\n",
        "\n",
        "Second time running:\n",
        "0.00956869125366211 seconds\n",
        "\n",
        "Third time:\n",
        "0.005471467971801758 seconds\n",
        "\n",
        "0.009866952896118164 seconds \n",
        "0.00510859489440918 seconds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (1, 1, 4, 2)\n",
        "x = tf.ones(input_shape)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRO2YFOhbzlu",
        "outputId": "ffb85eb9-5fd8-43c0-f550-a6fb199f7975"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[1. 1.]\n",
            "   [1. 1.]\n",
            "   [1. 1.]\n",
            "   [1. 1.]]]], shape=(1, 1, 4, 2), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}